{
    "contents" : "source( \"helpers.R\" )\n## --- IMPORT DATA --- \n  ## Step 1: copy data to excel spreadsheet\n  \n  ## Step 2: remove all formatting via clear>all formatting.\n  ##  make sure that date-time fields are in excel number format i.e. 40802.09\n  ##  make sure that all \"\" values are replaced with null in excel\n  ##   copy data set into new sheet--values only > click find > search for \"\" text > replace with \"null\" (check match entire contents) > replace \"null\" with blank\n  \n  raw <- import_raw( \"Data.csv\" )\n\n## --- COPY DATA SET ---\n\n  copy <- as.data.table( raw )\n\n## --- REMOVE UNDESIRED VARIABLES ---\n\n## --- TRANSFORM / RESHAPE DATA ---\n\n  \n\n  ## --- CONSOLIDATE AND PRINT ---\n\n  ## export data to csv\n  fileName = \"filtered\"\n  fileExt = \".csv\"\n  write.table( copy.selected, \n               file      = paste( \"./\", fileName, fileExt ), \n               sep       = \",\",\n               row.names = TRUE, \n               col.names = NA )\n\n  \n## --- GENERATE GRAPHS ---\n  DT <- copy( copy )\n\n\n## --- ADD ADDITIONAL FIELDS ---\n\n  start_DT <- as.excel_DT( \"07/01/2014 12:00:00 AM\" )\n  stop_DT <- as.excel_DT( \"07/01/2015 12:00:00 AM\" )\n  \n  intervals <-\n    seq(from = start_DT,\n        to = stop_DT,\n        by = 15 / (24 * 60))\n  \n  ## decide which hours to exclude\n  intervals <- Filter(function(x) {\n    mod(x, 1) >= 6 / 24  && mod(x, 1) <= 20 / 24\n  },\n  intervals)\n  \n  ## creat a table of the intervals and add a census field\n  census <- data.table( intervals )\n  census[, \":=\" ( census, -1 ) ]\n  \n  \n  ## calculates census for each time stamp in the census data table using provided start, stop times\n  calc_census <- function( census_DT, DT.Start, DT.Stop ) {\n    for (i in seq_along(census_DT$intervals)) {\n      set(census_DT,\n          i = i,\n          j = 2,\n          value = sum(\n            1 * (\n              census_DT$intervals[i] >= DT.Start &\n                census_DT$intervals[i] < DT.Stop\n            )\n          ))\n    }\n    census_DT\n  }\n  \n  \n  ## converte inverval times to POSIXlt to get convenient date properties\n  temp <- as.POSIXlt(\n    as.POSIXct(intervals * (60 * 60 * 24),\n               origin = \"1899-12-30\",\n               tz = \"GMT\"),\n    origin = \"1899-12-30\", tz = \"GMT\"\n  )\n\n  ## add date properties to census data table\n  census[, c(\"mday\",\n             \"wday\",\n             \"yday\",\n             \"month\",\n             \"year\",\n             \"hour\" ) := list(temp$mday,\n                             ifelse( temp$wday == 0, 7, temp$wday ),\n                             1 + temp$yday,\n                             1 + temp$mon,\n                             1900 + temp$year,\n                             temp$hour )]\n  \n  ## calculate week of the month field (derived from excel formula)\n  census[, c(\"WoM\") := list((mday + ifelse(\n    as.POSIXlt(\n      paste(year, month, 1, sep = \"-\"), origin = \"1899-12-30\", tz = \"GMT\"\n    )$wday == 0, 7, as.POSIXlt(\n      paste(year, month, 1, sep = \"-\"), origin = \"1899-12-30\", tz = \"GMT\"\n    )$wday\n  ) - 1) %/% 7 + 1)]\n  \n  \n## --- CALCULATE CENSUS DATA ---\n  # install.packages( \"curry\" )\n  library( curry )\n  \n  ## select only data from Pacific\n  DT.PAC <- DT[FileName == \"PAC_OR_VNG_20140701-20150630_EPIC\",\n               j = list(\n                 X_ID, FileName, Provider, Service, Room.Name, Std.Pt.Type,\n                 ASA, Wheels.in.Wheels.out...mins., Proc.Start.DT, Proc.Stop.DT\n               )]\n  \n  ## cross join all possible unique selections from services and rooms\n  selections_DT <- CJ( unique( DT.PAC$Service ), unique( DT.PAC$Room.Name ) )\n  \n  for (i in seq_along( selections_DT$V1)) {\n    for_each_selected_census( selections_DT[i], DT.PAC, census )\n  }\n  \n  \n  for_each_selected_census <- function( selections, DT, census ) {\n    ptm <- proc.time()\n    \n    cat <- selections$V1\n    Rm <- selections$V2\n    DT.Svc.Rm <- DT[ Service == cat & Room.Name == Rm ]\n    calc_census( census[, c( \"category\", \"Room\" ) := list( cat, Rm ) ], \n                 DT.Svc.Rm$Proc.Start.DT, \n                 DT.Svc.Rm$Proc.Stop.DT ) %>%\n      my_export( paste( cat, Rm, \"census\", sep = \"_\" ) )\n    \n    print( proc.time() - ptm )\n  }\n  \n## --- IMPORT AND COMBINE DATA ---\n\n  ## import file names--only with .csv extension\n  filenames <- list.files( path = \"C:\\\\Users\\\\glseanb\\\\Google Drive\\\\R\\\\Workspace\\\\2017-01 Sutter VNG (analysis 3)\\\\results\\\\\",\n                           pattern = \"_census_table .csv$\",\n                           full.names = TRUE )\n  \n  ## helper function to reduce/combine data sets to one\n  my.combine <- function( x ) { Reduce( rbind, x ) }\n  my.read <- (function( x ) {\n    # read file\n    dat <- read.csv( file = x,\n                       stringsAsFactors = F,\n                       header = F,\n                       skip = 1 )\n    # get the file name and add it as a column to the dataframe\n    dat$file <- strsplit( x, \"\\\\\\\\\" )[[1]][length( strsplit( filenames[1], \"\\\\\\\\\" )[[1]] )]\n    dat\n  })\n  \n  ## read in all files\n  combined <- filenames %>%\n    lapply( my.read ) %>%\n    my.combine()\n  \n  ## reassign proper names for each field\n  setnames( combined, 1:12, c( \"X_ID\",\n                               \"intervals\",\n                               \"census\",\n                               \"mday\",\n                               \"wday\",\n                               \"yday\",\n                               \"month\",\n                               \"year\",\n                               \"hour\",\n                               \"WoM\",\n                               \"category\",\n                               \"Room\" ) )\n  \n  wide <- dcast( combined, category + wday + Room + WoM + hour ~ ., \n                 fun.aggregate = function( x ){ sum( x ) / length( x ) }, value.var = \"census\" )\n  \n  my_export( wide, \"combined_wide_census\" )\n  ",
    "created" : 1484691475265.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1905087906",
    "id" : "407D9F3D",
    "lastKnownWriteTime" : 1484263341,
    "path" : "C:/Users/glseanb/Google Drive/R/Workspace/2017-01 Sutter VNG (analysis 3)/analysis.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_source"
}